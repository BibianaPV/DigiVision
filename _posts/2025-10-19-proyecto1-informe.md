---
layout: post
title: ""
date: 2025-10-19
---
<style>
.page-content {
  max-width: 100% !important;
  width: 100% !important;
  padding: 0 !important;
  margin: 0 !important;
}

.wrapper {
  max-width: 100% !important;
  width: 100% !important;
  padding: 0 !important;
  margin: 0 !important;
}
.full-width-section {
  width: 90%;
  max-width: 100%;
  margin: 0 auto;
  padding: 0;
  box-sizing: border-box;
}
/* Contenedor principal que aloja √≠ndice y contenido */
.main-container {
  display: flex;
  gap: 25px;              /* espacio entre √≠ndice y contenido */
  align-items: flex-start; /* alinea arriba ambos */
}

/* √çndice lateral */
.toc-container {
  flex: 0 0 320px;         /* ancho fijo de 220px */
  position: sticky;
  top: 20px;
  max-height: 90vh;
  overflow-y: auto;
  background: #f8f9fa;
  padding: 10px;
  border-right: 2px solid #ddd;
}

/* Contenido principal */
.post-content {
  flex: 1;                /* ocupa todo el espacio restante */
  text-align: justify;
  min-width: 0;           /* üëà evita que el contenido se desborde */
}

/* Estilo √≠ndice */
.toc-container ul {
  list-style: none;
  padding-left: 0;
}

.toc-container li a {
  text-decoration: none;
  color: #004aad;
}

.toc-container li a:hover {
  text-decoration: underline;
}

/* Dise√±o responsive para pantallas peque√±as */
@media (max-width: 1200px) {
  .main-container {
    flex-direction: column;
  }
  .toc-container {
    width: 100%;
    border-right: none;
    border-bottom: 2px solid #ddd;
    max-height: none;
    overflow: visible;
  }
}
</style>

<div class="full-width-section">
<div markdown="1" class="main-container">
<div markdown="1" class="toc-container">
## Contenido
* TOC
{:toc}
</div>

<!-- Contenido principal -->
<div markdown="1" class="post-content">

# **Informe Proyecto 1**

# **1\. Introducci√≥n**

La visi√≥n por computador es una herramienta fundamental que permite procesar y obtener informaci√≥n a partir de im√°genes digitales. Para garantizar la precisi√≥n geom√©trica de las mediciones, la calibraci√≥n de c√°mara permite estimar par√°metros intr√≠nsecos, corregir distorsiones y establecer la relaci√≥n entre coordenadas reales y de imagen (Zhang, 2000; Duisterhof et al., 2022).

Por otro lado, las transformaciones geom√©tricas permiten alinear y manipular la disposici√≥n de los objetos. Adicionalmente, las transformaciones de intensidad como brillo, contraste y correcci√≥n gamma mejoran la visibilidad y compensan diferentes condiciones lum√≠nicas (Gonzalez & Woods, 2018). Mientras que obtener la frecuencia de distribuci√≥n de la intensidad (histograma) y su ecualizaci√≥n permite mejorar el contraste (Patel et al., 2013).

Finalmente, la segmentaci√≥n por color permite aislar y cuantificar regiones de inter√©s. Estas t√©cnicas representan el conjunto de herramientas aplicadas en este proyecto para mejorar, analizar y procesar im√°genes.

# **2\. Marco Te√≥rico**

## 2.1 Calibraci√≥n de la C√°mara

Uno de los primeros procesos en el manejo de im√°genes digitales, es la calibraci√≥n de la lente, Actualmente, existen cientos de modelos de c√°maras, con par√°metros y caracter√≠sticas distintos. Conocer de antemano sus par√°metros y de qu√© manera este dispositivo transfiere la informaci√≥n del mundo real **(3D)** como una imagen digital **(2D)**.

Dado que en la mayor√≠a de los casos las caracter√≠sticas de una c√°mara digital nos son desconocidas o inaccesibles, recurrimos a m√©todos pr√°cticos y simulados para tener una estimaci√≥n. Con la utilizaci√≥n de un patr√≥n espec√≠fico, en este caso un **tablero de ajedrez** con esquinas rectas y de un largo conocido y definido previamente, buscamos modelar las distorsiones reales que percibe la c√°mara al tomar una foto. (Sattia Mallyk, Kaustubh Sadekar, 2020\)

Realizando m√∫ltiples im√°genes sucesivas desde diferentes √°ngulos y distancias del mismo patr√≥n, es posible modelar artificialmente estas distorsiones que introduce la lente y determinar con elevada precisi√≥n como la c√°mara proyecta puntos en el espacio de la imagen.

Este proceso permite corregir errores de distorsi√≥n y establecer un modelo matem√°tico que describe el comportamiento de la c√°mara, lo cual es crucial para aplicaciones en visi√≥n por computadora, reconstrucci√≥n 3D, fotogrametr√≠a, rob√≥tica, y otras √°reas donde se requiere precisi√≥n geom√©trica.

Los datos que sacaremos de esta calibraci√≥n los conoceremos como par√°metros intr√≠nsecos y ser√°n: 

* **f‚Çì, f·µß**: distancia focal (en p√≠xeles) en los ejes x e y.  
* **c‚Çì, c·µß**: coordenadas del punto principal (centro √≥ptico en la imagen).  
* **s**: coeficiente de sesgo (skew), usualmente 0 si los ejes est√°n ortogonales.

K \= (fx   s   cx), (0,  fy,  cy), (0,  0,  1\)

## 2.2 Transformaciones de intensidad 

Operaciones puntuales que modifican directamente los valores de intensidad de los p√≠xeles de una imagen, sin alterar su posici√≥n ni estructura espacial (Gonzalez & Woods, 2018). Su objetivo es mejorar la apariencia visual, facilitar el an√°lisis o resaltar detalles espec√≠ficos. Pueden ser:

* **Lineales:** como el ajuste de brillo y contraste. El brillo se modifica sumando una constante Œ≤ a cada p√≠xel, desplazando la distribuci√≥n de intensidades: 

ùêºo(x,y)=I(x,y)+ùõΩ

donde Œ≤ es una constante de desplazamiento (positiva para aclarar, negativa para oscurecer).

El contraste se modifica mediante un factor multiplicativo Œ±, que expande o comprime la distribuci√≥n alrededor de un valor medio.

Io‚Äã(x,y)=Œ±‚ãÖ(I‚Äã(x,y)‚àím)+m

Donde, Œ± es el factor de contraste y m es un punto medio que permanece constante. 

* **No lineales:** como la correcci√≥n gamma, que ajusta la luminancia percibida aplicando una potencia Œ≥ sobre cada valor de intensidad normalizado.

Io(x,y)‚Äã=c‚ãÖ(I(x,y)‚Äã)

Donde c es una constante de escala y Œ≥ el exponente de correcci√≥n. Si Œ≥\<1, los tonos oscuros se elevan; si Œ≥\>1, los tonos claros se comprimen.

## 2.3 Transformaciones geom√©tricas

Las transformaciones geom√©tricas son operaciones fundamentales en el procesamiento de im√°genes,entre las m√°s comunes est√°n la traslaci√≥n y la rotaci√≥n, donde, estas transformaciones se representan mediante matrices en coordenadas homog√©neas que modifican la relaci√≥n espacial entre p√≠xeles (Herrera, Guijarro, Guerrero, Jos√©. (2016). 

Matem√°ticamente, estas transformaciones se representan mediante matrices en coordenadas homog√©neas: traslaci√≥n por vector (tx, ty); rotaci√≥n por √°ngulo Œ∏, escala por factores (sx, sy). La composici√≥n de transformaciones se obtiene mediante multiplicaci√≥n de matrices y el orden importa: rotar y luego trasladar no es equivalente a trasladar y luego rotar.


## 2.4 Distribuci√≥n de intensidades

El histograma de intensidades es una representaci√≥n estad√≠stica que muestra la frecuencia con la que aparecen distintos niveles de intensidad en una imagen (Gonzalez & Woods, 2018). As√≠,

h(rk‚Äã)=nk‚Äã

donde rk‚Äã es el nivel de intensidad y nk‚Äã el n√∫mero de p√≠xeles con esa intensidad. Al normalizar se obtiene una funci√≥n de probabilidad discreta:

p(rk‚Äã)=nk/n‚Äã‚Äã

La distribuci√≥n del histograma permite identificar caracter√≠sticas como brillo, contraste y rango din√°mico. Por ejemplo, un histograma agrupado en intensidades bajas indica una imagen oscura; en altas intensidades indica una imagen clara y uno distribuido uniformemente indica buen contraste (Patel et al., 2013).

La funci√≥n de distribuci√≥n acumulada (CDF) se obtiene a partir del histograma y representa la probabilidad acumulada de que un p√≠xel tenga una intensidad menor o igual a un cierto valor. Se define como:

CDF(rk‚Äã)=‚àëp(rj‚Äã)

La CDF es fundamental en t√©cnicas de ecualizaci√≥n de histograma, permitiendo construir una transformaci√≥n de intensidades que redistribuye los niveles originales de manera m√°s uniforme a lo largo del rango din√°mico de la imagen (Gonzalez & Woods, 2018). Para esto se busca construir una funci√≥n de transformaci√≥n T(r) que mapee los niveles de intensidad originales r en nuevos niveles s, de manera que la distribuci√≥n de salida se acerque a una distribuci√≥n uniforme:

s=T(r)=(L‚àí1)‚ãÖCDF(r)

Donde L es el n√∫mero total de niveles de intensidad.

## 2.5 Segmentaci√≥n de Imagenes por colores

La **segmentaci√≥n** es una t√©cnica del procesamiento digital de im√°genes, en la que buscamos dividir una imagen en regiones o segmentos que comparten caracter√≠sticas comunes, como color, intensidad o textura (Gonzalez & Woods, 2018). 

Dentro de este contexto la segmentaci√≥n basada en el color permite identificar y extraer objetos de una imagen digital utilizando la informaci√≥n disponible en los p√≠xeles. Para ello, es com√∫n trabajar en espacios de color distintos al RGB.

Aunque el espacio **RGB** es ampliamente utilizado en la visualizaci√≥n de im√°genes, para este ejercicio se requerir√° de m√°s precisi√≥n y lidiar con cambios en la intensidad de la luz. Para esto se utiliza el formato **HSV** (Hue, Saturation, Value), ya que este √∫ltimo separa la tonalidad del color de la intensidad, facilitando as√≠ una detecci√≥n m√°s robusta frente a variaciones de luz (Color Identification in Images using Python \- OpenCV, 2023).

# **3\. Metodolog√≠a**

## 3.1 Calibraci√≥n de la C√°mara

Nos preparamos para la realizaci√≥n del ejercicio desactivando en nuestra c√°mara las funciones que puedan obstruir las mediciones (HDR, AutoFocus, Zoom Digital), completado esto, pondremos el **patr√≥n de ajedrez** sobre una superficie plana y realizaremos diferentes fotograf√≠as desde distintos √°ngulos, teniendo el patr√≥n dentro del encuadre, previamente deberemos haber realizado mediciones de uno de los lados de un cuadrado.

Un paso de validaci√≥n es necesario antes de buscar los par√°metros intr√≠nsecos, utilizando  la funci√≥n *cv2.findChessboardCorners()* de la biblioteca OpenCV, buscamos detectar las esquinas del patr√≥n, si estas esquinas no son detectadas no podremos realizar el siguiente paso por lo que deberemos repetir las im√°genes.

Utilizando la medida del cuadrado en **mm** como referente, utilizaremos *cv2.calibrateCamera()* para encontrar los par√°metros intr√≠nsecos, esta funci√≥n nos devolver√° los datos que estamos buscando y nos permitir√° guardarlo en un archivo aparte para su utilizaci√≥n posterior.

## 3.2 Transformaciones de intensidad 

![image1](/DigiVision/proyecto1/support_files/tranformacionIntensidadesMetodologia.jpg)  
Estas operaciones se realizaron a nivel de p√≠xel y fueron programadas utilizando las librer√≠as de NumPy, Matplotlib y Pillow.

## 3.3 Transformaciones geom√©tricas

1. Prepareci√≥n de la immagen: se carg√≥ la imagen y posteriromente se conviriti√≥ en RGBA.
2. Definici√≥n de la transformaciones: se construy√≥ una lista con 5‚Äì8 configuraciones (tx, ty, Œ∏, s). Cada configuraci√≥n produce un frame.  
3. Ejecuci√≥n de transformaciones:  
   \- Escala (factor s) aplicada con interpolaci√≥n bic√∫bica.  
   \- Rotaci√≥n sobre el centro (expand=True para evitar recortes).  
   \- Pegado de la imagen rotada en un lienzo del tama√±o original y aplicaci√≥n de la traslaci√≥n (tx, ty).  
4. Guardar: cada frame se guarda como PNG numerado.  
5. Generaci√≥n del GIF usando imageio, ajustando \`duration\` para la velocidad.  

## 3.4 Distribuci√≥n de intensidades

Utilizando las im√°genes obtenidas en el punto 3.2 se busca comparar c√≥mo var√≠a el contraste en im√°genes bien iluminadas frente a aquellas con baja luminosidad y hacer su respectiva correcci√≥n. Para esto, las im√°genes RGB fueron convertidas a escala de grises. Luego, utilizando la funci√≥n np.hist() se calcul√≥ el histograma para cada una de las im√°genes, lo que permiti√≥ comparar su distribuci√≥n de intensidad inicial.

Posteriormente, se calcul√≥ la funci√≥n de distribuci√≥n acumulada (CDF) utilizando hist.cumsum() y se normaliza para garantizar un mapeo correcto entre 0 y 255\. Finalmente, cada valor de intensidad original se reemplaz√≥ por su nuevo valor transformado mediante indexaci√≥n directa, obteniendo la imagen ecualizada. 

Las im√°genes obtenidas fueron guardadas en la carpeta  *results/.*

## 3.5 Segmentaci√≥n por Colores

Con el objetivo de identificar colores espec√≠ficos en una imagen digital, decidimos emplear una combinaci√≥n de **m√°scaras de color** y **Canny** para la detecci√≥n de bordes. La idea principal se basaba en separar los tres colores primarios del espacio RGB (rojo, verde y azul) y, a partir de esta segmentaci√≥n, resaltar con l√≠neas los objetos que presentaran una mayor intensidad en dichos colores.

Inicialmente, realizamos una prueba con **rangos de valores bajos y altos en RGB** para crear m√°scaras que filtraran las regiones espec√≠ficas. No obstante, los resultados fueron que los bordes obtenidos no eran n√≠tidos ni representativos, y se manten√≠a la presencia de ruido o √°reas que no correspond√≠an a los colores buscados.

Tras una revisi√≥n de documentaci√≥n y recursos disponibles, encontramos diversas recomendaciones que suger√≠an utilizar el espacio de color **HSV en lugar de RGB**, debido a su **mayor precision** y su capacidad para separar la informaci√≥n de tono, saturaci√≥n e intensidad (Color Identification in Images using Python \- OpenCV, 2023).

Con esta informaci√≥n, definimos **rangos espec√≠ficos en HSV** para rojo, verde y azul, generamos m√°scaras para cada uno utilizando la funci√≥n *cv2.inRange()*. A continuaci√≥n, aplicamos estas m√°scaras a la imagen original para segmentar las regiones correspondientes a cada color.

Una vez segmentadas las regiones de inter√©s, desarrollamos un m√©todo personalizado para **dibujar, se√±alar y analizar los objetos detectados**. Este m√©todo inclu√≠a los siguientes pasos:

* **Aplicaci√≥n de desenfoque gaussiano** a las m√°scaras para eliminar el ruido.  
* **Detecci√≥n de bordes** mediante el algoritmo de Canny.  
* **Detecci√≥n de contornos** usando *cv2.findcontourns()*.  
* **C√°lculo de √°reas en p√≠xeles** para cada contorno detectado.  
* **Aplicaci√≥n de un filtro de tama√±o (size filter)** con el fin de eliminar contornos demasiado grandes o irrelevantes que no correspondiera a objetos v√°lidos dentro del an√°lisis.

# **4\. Resultados y An√°lisis**

## 4.1 Calibraci√≥n de la C√°mara

El ejercicio de calibraci√≥n fue llevado a cabo con 5 im√°genes con la c√°mara se un celular modelo Samsung Galaxy S7, los resultados mostraron una deformaci√≥n en forma de coj√≠n al ver como las im√°genes se hunde de cierta forma en el centro de cada lado de la im√°gen dando la impresi√≥n de un coj√≠n.

A parte de esta deformaci√≥n que es el aspecto m√°s visual, vamos a encontrar como ciertos valores presentan ligeras variaciones, uno de estos casos es el del *focal length* en el cual tenemos los siguientes resultados: 

(fx \= 3.16386392e+03 , fy \= 3.18629093e+03)

Estos valores pueden ser en la mayor√≠a de los casos iguales, estos dos puntos representan las direcciones en **x** y en **y** que podr√°n diferir dependiendo del tama√±o de los p√≠xeles de la c√°mara, otro valor a tener en cuenta es el de cx y cy los cuales nos dieron como resultado.

(cx, cy) \= (2.00104091e+03 , 1.55433682e+03)

Tenemos que tanto cx y cy que ser√≠an las coordenadas del centro √≥ptico que hemos sacado de acuerdo a la calibraci√≥n, estos dos puntos est√°n relativamente cerca del centro original aunque notamos una mayor variaci√≥n en los valores de y, lo cual podr√≠a deberse al hecho de que son los lados superior e inferior los que presenta una mayor deformaci√≥n en las im√°genes corregidas.

cx \=2.00104091e+03  \=  2.00104091 x 10¬≥ 

cx \= 2001.04091

cy \=1.55433682e+03  \=  1.55433682 x 10¬≥ 

cy \=  1554.33682

(cx, cy) \= 2001.04091, 1554.33682 

(ix, iy) \=2016, 1512 

Tenemos entonces que ix e iy representan el centro seg√∫n las dimensiones originales de la imagen en este caso estar√≠amos hablando de que cx est√° a 14 pixeles a la izquierda del centro de la imagen y que y el cual est√° m√°s separado, est√© 42 pixeles por encima del centro de la imagen.

d \= (cx-ix)2+(cy-iy)2= 44.87 pixeles de diferencia

Lo m√°s a destacar de los resultados es la variaci√≥n en y, tanto en la **distancia focal** como en la distancia del centro de la c√°mara al centro de la imagen que presenta una variaci√≥n mayor, esto nos hace intuir que los p√≠xeles de la c√°mara presenta un tama√±o mayor en su altura dando lugar a estas variaciones.

![image9](/DigiVision/proyecto1/results/1.calibracionCamara/20251010_160324_undistorted.jpg)

## 4.2 Transformaciones de intensidad

**Brillo**  

![image2](/DigiVision/proyecto1/results/2.transformacionesIntensidad/comparacionBrillo.png) 

Se puede observar en la imagen de la fachada AM al utilizar un beta negativo la imagen se oscurece de manera global, desplazando la distribuci√≥n de intensidades hacia valores m√°s bajos. Mientras que en la imagen de la fachada PM con un beta positivo se desplazan las intensidades hacia valores m√°s altos, la imagen se aclara, es decir, se produce un aumento del brillo general. 

**Contraste** 

![image3](/DigiVision/proyecto1/results/2.transformacionesIntensidad/compracionContraste.png)  

En la fachada AM al aplicar un Œ±=2 y un punto medio de 0.5, se produce una mayor diferencia entre las intensidades, las regiones claras (como el cielo y las fachadas) se vuelven m√°s brillantes, mientras que las zonas oscuras (√°rboles) se oscurecen a√∫n m√°s. Esto incrementa el contraste global, pero tambi√©n puede generar p√©rdida de detalle en zonas oscuras debido a la saturaci√≥n.

En la fachada PM al aplicar un Œ±=-1 y un punto medio de 0.5, la relaci√≥n se invierte respecto al punto medio generando un efecto negativo, las zonas oscuras se vuelven claras y viceversa.

**Correcci√≥n Gama**  

![image4](/DigiVision/proyecto1/results/2.transformacionesIntensidad/comparacionGamma.png) 

Para la imagen de la fachada AM, al aplicar un factor gamma Œ≥=2 con una constante c=1 se genera un oscurecimiento. Esto se debe a que los valores de intensidad inferiores a 1 se elevan a una potencia mayor lo que desplaza parte del rango din√°mico hacia valores m√°s bajos. Esto produce una p√©rdida de detalle en las zonas oscuras y del primer plano.

Para la imagen de la fachada PM, al aplicar un factor gamma Œ≥=2 con una constante c=1 se produce un efecto de aclarado no lineal, ya que los valores bajos se amplifican al elevarlos a un exponente menor que 1\. Esto mejora la visibilidad de detalles en regiones oscuras, como en los √°rboles y las fachadas inferiores, sin sobreexponer las zonas ya iluminadas como las ventanas.

**Operaciones aritm√©ticas**

![image5](/DigiVision/proyecto1/results/2.transformacionesIntensidad/operacionesAritmeticas.png) 

La suma de ambas im√°genes produce un incremento en la intensidad al combinar los valores de brillo de las dos im√°genes. As√≠, la imagen se ve m√°s clara y brillante, con detalles visibles en los √°rboles y  la fachada. Tambi√©n, se observa saturaci√≥n en las regiones m√°s iluminadas como el cielo y reflejos.

La resta realza las diferencias entre ambas im√°genes evidenciando zonas en las que la iluminaci√≥n cambia significativamente entre el d√≠a y la noche. Se observan cambios en el cielo y zonas oscuras en la fachada donde hab√≠a m√°s iluminaci√≥n en la noche.

La multiplicaci√≥n pixel a pixel genera una imagen m√°s oscura ya que intensidades menores a 1 reducen a√∫n m√°s el resultado. Se observa una p√©rdida de detalle en toda la imagen especialmente en las zonas m√°s oscuras y alcanza a evidenciar levente un realce en la zona donde hay iluminaci√≥n alta en ambas im√°genes.

La divisi√≥n amplifica intensidades cuando los valores en la imagen PM son peque√±os y disminuye las intensidades cuando los valores de la imagen PM son grandes. En este caso, la imagen de la fachada PM tiene valores bajos de intensidad lo que amplifica las intensidades dando como resultado una imagen fuertemente aclarada y contrastada, con zonas de saturaci√≥n extrema en √°rboles y fachada. 

## 4.3 Transformaciones geom√©tricas

Este ejercicio permiti√≥ observar c√≥mo las transformaciones geom√©tricas influyen en la apariencia y trayectoria de una imagen aplicadas de forma sucesiva. El orden de las operaciones es muy importante, ya que, modificar la secuencia entre escala, rotaci√≥n y traslaci√≥n cambia bastante la posici√≥n final de los p√≠xeles.

La funci√≥n **transform** es la que permite ajustar el tama√±o mediante escalado, girarla seg√∫n el √°ngulo de rotaci√≥n y desplazarla en el plano mediante traslaci√≥n. Para evitar que la imagen recortada pierda informaci√≥n, se crea un lienzo del tama√±o original donde se pega la versi√≥n transformada de la imagen, garantizando que  la imagen permanezca dentro de los l√≠mites visibles, siendo esto una herramienta esencial en visi√≥n por computadora que permite modelar c√≥mo un sistema percibe los objetos independientemente de su posici√≥n, tama√±o u orientaci√≥n.

![image6](/DigiVision/proyecto1/results/3.transformacionesRotaci√≥nTraslaci√≥n/frames/frame_01.png)
![image7](/DigiVision/proyecto1/results/3.transformacionesRotaci√≥nTraslaci√≥n/frames/frame_04.png)
![image8](/DigiVision/proyecto1/results/3.transformacionesRotaci√≥nTraslaci√≥n/frames/frame_06.png)

La funci√≥n **generate_transform_sequence** se encarga de aplicar varias transformaciones a una imagen y crear un GIF animado con todo el proceso. Con la imagen principal (base), le va aplica distintos cambios como moverla, girarla y escalarla, guardando cada paso como una imagen separada (frames). Luego, con la librer√≠a imageio, se juntan todos los frames como una animaci√≥n, mostrando de forma visual c√≥mo la imagen se va transformando poco a poco.


![image9](/DigiVision/proyecto1/results/3.transformacionesRotaci√≥nTraslaci√≥n/frames/transformations.gif)


## 4.4 Distribuci√≥n de intensidades

![image10](/DigiVision/proyecto1/results/4.distribuci√≥nIntensidad/histogramas.png) 

Para la fachada AM el histograma tiene una distribuci√≥n a lo largo de todo el rango din√°mico con un aumento en valores bajos. Aunque la imagen tiene zonas oscuras como los √°rboles cuenta con una iluminaci√≥n m√°s equilibrada que incluye intensidades medias y altas. Por el contrario, en la imagen de la fachada PM el histograma se concentra principalmente en intensidades bajas, lo que refleja una escena predominantemente oscura.

![image11](/DigiVision/proyecto1/results/4.distribuci√≥nIntensidad/CDF%20Normalizada.png)

la CDF en el caso  AM el aumento fue m√°s constante con una peque√±a meseta \~ 100 y 200 y un aumento casi lineal al final, mientras que en el caso PM se evidenci√≥ un cambio m√°s pronunciado al inicio y una meseta \~ desde 100, lo que evidencia un aumento de intensidades en las zonas m√°s oscuras de la imagen.

![image12](/DigiVision/proyecto1/results/4.distribuci√≥nIntensidad/Im√°genesEcualizadas.png)

En la imagen AM, la distribuci√≥n de intensidades ya era amplia y la transformaci√≥n de ecualizaci√≥n fue m√°s suave, con cambios leves en los niveles de intensidad y un incremento moderado del contraste.

Por otro lado, en la imagen PM, el histograma estaba concentrado en intensidades bajas, la CDF extendi√≥ significativamente estos valores hacia todo el rango din√°mico, generando un aumento fuerte del contraste.

## 4.5 Segmentaci√≥n por Colores

El resultado obtenido demuestra que el sistema de segmentaci√≥n implementado es capaz de **delimitar los contornos** de los objetos presentes en la imagen, independientemente de su ubicaci√≥n relativa (cercana o lejana) dentro del campo visual.

Adem√°s, el algoritmo desarrollado no solo segmenta los colores objetivo (rojo, verde y azul), sino que tambi√©n logra **resaltar cada regi√≥n con l√≠neas de contorno claramente visibles**, aplicando un grosor que mejora la percepci√≥n visual de los l√≠mites detectados.

Este comportamiento es posible gracias a la combinaci√≥n de varias t√©cnicas implementadas:

* La utilizaci√≥n del **espacio de color HSV**, que permite una detecci√≥n m√°s robusta de los colores frente a variaciones de iluminaci√≥n.  
* La aplicaci√≥n de **desenfoque gaussiano** que elimina el ruido en las m√°scaras.  
* El uso del algoritmo de **detecci√≥n de bordes de Canny** y *cv2.findContours()* para obtener contornos n√≠tidos y precisos.  
* La visualizaci√≥n final con *cv2.drawContours()* o funciones similares, que permiten resaltar cada objeto con trazos diferenciados y adaptativos.

En conjunto, estos resultados validan que el sistema desarrollado no solo es funcional, sino que es capaz de realizar una **detecci√≥n y visualizaci√≥n efectiva** de los colores de inter√©s, as√≠ como el c√°lculo de su √°rea y conteo de los bordes detectados.

![image13](/DigiVision/proyecto1/results/5.segmentacion/resultado_segmentacion.jpg)

# **5\. Referencias Bibliogr√°ficas**

Zhang, Z. (2000). *A flexible new technique for camera calibration*. IEEE TPAMI.

Gonzalez, R. C., & Woods, R. E. (2018). *Digital Image Processing*. Pearson.

Herrera, P. J., Guijarro, M., & Guerrero, J. M. (2016). Operaciones de transformaci√≥n de im√°genes. En Conceptos y m√©todos en visi√≥n por computador (cap. 4). Madrid, Espa√±a: Universidad Francisco de Vitoria.

Patel, O. et al. (2013). *SIPIJ*, 4(5).

Vinayak Ray (03 de Enero de 2023). Color Identification in Images using Python \- OpenCV. GeeksforGeeks. [https://www.geeksforgeeks.org/python/color-identification-in-images-using-python-opencv/](https://www.geeksforgeeks.org/python/color-identification-in-images-using-python-opencv/) 

Gururaj (26 de septiembre de 2024). Choosing the correct upper and lower HSV boundaries for color detection with cv::inRange (OpenCV).  
[https://www.geeksforgeeks.org/computer-vision/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-with-cv-inrange-opencv/](https://www.geeksforgeeks.org/computer-vision/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-with-cv-inrange-opencv/)

priyarajtt (15 de Julio de 2025). Camera Calibration using Python \- OpenCV. GeeksforGeeks. [https://www.geeksforgeeks.org/python/camera-calibration-with-python-opencv/](https://www.geeksforgeeks.org/python/camera-calibration-with-python-opencv/)

Kaustubh Sadekar, Satya Mallick (25 de Febrero del 2020\) Camera Calibration using OpenCV. [https://learnopencv.com/camera-calibration-using-opencv/](https://learnopencv.com/camera-calibration-using-opencv/) 

# **6\. Reporte de Contribuci√≥n Individual**

| Estudiante | Aporte Personal |
| :------ | :---- |
| Leidy Marcela Leal Loaiza | Ejercicio de Transformaciones geom√©tricas|
| Juan Felipe Arbelaez | Ejercicio de Calibraci√≥n de C√°mara y Segmentaci√≥n por colores. |
| Bibiana Andrea Pe√±a V | transformaci√≥n de intensidades y la ecualizaci√≥n del histograma para mejorar el contraste de las im√°genes, incluyendo la implementaci√≥n y validaci√≥n del procedimiento. Adem√°s, particip√© en la redacci√≥n del informe final y en la organizaci√≥n de los archivos comunes del proyecto, contribuyendo a mantener una estructura clara y coherente para el trabajo en equipo. |

<p style="text-align:center;">
  <a href="{{ "/" | relative_url }}">‚¨Ö Volver al inicio</a>
</p>

</div>
</div>
</div>
